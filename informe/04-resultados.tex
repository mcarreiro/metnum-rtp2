\section{Experimentación Y Resultados}

  Los algoritmos previamente detallados tienen muchos puntos a testear. Veamos cada uno de estos en forma detallada y con los resultados intentemos responder a la pregunta original: ¿qué estrategia debo tomar para posicionar mi sitio en internet?

  \begin{itemize}
    \item{Convergencia de Page Rank}
    \item{Convergencia de Hits}
    \item{Comparación de tiempos}
  \end{itemize}


\subsection{Casos de prueba}
   A continuación se listarán los casos utilizados en las experimentaciones para mayor comprensión de los casos.

	\begin{itemize}
		\item MOVIES: Este caso incluye 5797 páginas
		\item ABORTION: Este caso incluye 2293 páginas
		\item GENETIC: Este caso incluye 3468 páginas
		\item STANFORD: Este caso incluye 281903 páginas
		\item GOOGLE: Este caso incluye 916428 páginas
	\end{itemize}  

\subsection{Convergencia de Page Rank} 

La convergencia de dicho algoritmo ocurrirá cuando la norma Manhattan de los vectores de la iteración anterior y la del actual sea cero(o a un valor relativamente cerca, esta cercanía estará dada por una tolerancia que para los casos presentados son cero). Es ahí cuando tendremos la respuesta final.\\
Para evaluar el comportamiento de la norma manhattan variaremos la probabilidad del navegante aleatorio, el cual de ahora en más lo denotaremos como el parámetro \textbf{c}.\\
A continuación se muestran los resultados de como evoluciona la norma a lo largo de las iteraciones y como varía la misma con distintos c, y que luego discutiremos más adelante.
Cabe aclarar que expresamos los valores de la norma en escala logarítmica para una mejor visualización y para que se obtenga un mejor entendimiento de como disminuye de a varias magnitudes en cada iteración.


% \begin{figure}
% \begin{center}
       % \includegraphics[scale=0.5]{imagenes/pagerank_movies_norma.png}
        % \includegraphics[scale=0.5]{imagenes/pagerank_abortion_norma.png}
       % \end{center}
% \end{figure}

\begin{figure}[!htb]
\begin{center}
    % \includegraphics[scale=0.5]{imagenes/pagerank_google_norma.png}
  \includegraphics[scale=0.5]{imagenes/pagerank_stanford_norma.png}
    \end{center}
\end{figure}

De los casos de prueba presentados, agregamos solo este ya que el resto de los resultados eran iguales. Claramente notamos que la convergencia se retrasa más a medida que se agranda el c. 

\clearpage

\subsection {Convergencia de HITS}

La convergencia de dicho algoritmo ocurrirá cuando la norma Manhattan de los vectores x e y (que contienen el puntaje de los sitios de autoridad y los de hubs respectivamente) comparados con los de la iteración anterior 
sea cero para alguno de los dos(o a un valor relativamente cerca). Es ahí cuando tendremos la respuesta final.\\
Al igual que el algoritmo anterior utilizamos una tolerancia igual a cero.

A continuación se muestran los resultados para cuatro instancias distintas, 3 medianas y una grande, de como evoluciona la norma a lo largo de las iteraciones en ambos vectores :

\begin{figure}[!htb]
% \begin{center}
\begin{subfigure}{.5\textwidth}
       \includegraphics[scale=0.4]{imagenes/hits-abortion-expanded.png}
       \caption{Abortion expanded }
\end{subfigure}
  % \end{center}
% \end{figure}
% \begin{figure}
% \begin{center}
\begin{subfigure}{.5\textwidth}
        \includegraphics[scale=0.4]{imagenes/hits-genetic-expanded.png}
       \caption{Genetic expanded }
\end{subfigure}
       % \end{center}
% \end{figure}

% \begin{figure}[!htb]
% \begin{center}
\begin{subfigure}{.5\textwidth}
    \includegraphics[scale=0.4]{imagenes/hits-movie.png}
    \caption{Movies expanded }
\end{subfigure}
  % \end{center}
% \end{figure}
% \begin{figure}[!htb]
% \begin{center}
\begin{subfigure}{.5\textwidth}
    \includegraphics[scale=0.4]{imagenes/hits-stadfor.png}
    \caption{Standford}
\end{subfigure}
    % \end{center}
\end{figure}

En los últimos dos gráficos podemos observar drásticos descensos del valor de la norma cerca de la iteración 60 en el primero y de la 90 en el segundo. Esto es debido a que el valor de la norma es tan bajo que ya no es medible. Por lo tanto consideraremos que justo antes de esos descensos la norma ya convirgió.

\clearpage

\subsection{Comparación de Tiempos}

% El siguiente gráfico muestra la evolución del tiempo de computo en función del tamaño de la red para cada algoritmo. La red utilizada en todos los casos es una red estrella en la que todos los nodos (o sitios) apuntan al primero de ellos. Utilizamos este tipo de grafo ya que en c++ es el más rápido y simple de crear teniendo en cuenta además que la forma del grafo no tiene un impacto de eficiencia en los algoritmos sino su tamaño en nodos y aristas es el que cambia el tiempo de ejecución. Por esto no nos pareció pertinente probar distintos tipos de grafos (arboles, completos, bipartito, etc) sin más bien el tamaño de los mismos.

Hicimos unas primeras pruebas con dos grafos, uno chico y uno grande y notamos algo que se repitió en los otros ejemplos que tuvimos: Page Rank supera para grafos grandes ampliamente a Hits, y en grafos chicos se mantienen bastante cerca.

\begin{itemize}
\item{HITS (2000 nodos) $=$ 0.694 segundos }
\item{PAGE RANK (2000 nodos) $=$ 0.104 segundos }
\item{HITS (685230 nodos) $=$ 751.63 segundos }
\item{PAGE RANK (685230 nodos) $=$ 89.23 segundos }
\end{itemize}

Es por esto que decidimos hacer pruebas más genéricas con grafos generados aleatoriamente para corroborar esta hipótesis


 % \begin{figure}[!htb]
% \begin{center}
    % \includegraphics[scale=0.5]{imagenes/Tiempos.png}
    % \caption{Tiempo de ejecución en función del tamaño de la red}
    % \end{center}
% \end{figure}



